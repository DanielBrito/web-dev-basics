# Types of Testing Notes

## Unit Testing

Unit testing to focus on the smallest unit of a software. We are trying to isolate different areas, repeating until we test every module of the program. In this, we take a module, and we give it test cases. We then check these test cases against the oracle.

Overall, we are trying to make sure that the modules are doing what they were designed to do. We don't to have bugs from other modules ruin the module we are testing. So for unit tests, we typically supply dummy values to isolate the module. This way we know if a bug is happening, it's happening from the area we are testing.

More information: [Unit Testing](http://softwaretestingfundamentals.com/unit-testing/)

## Integration Testing

Integration testing is the next step. Once we are satisfied that the modules are all working how we want them, we need to begin testing them together. With integration testing, we begin testing the architecture and the communication as a whole.

Where in unit testing we came up with test cases for individual modules, with integration testing, we will come up with test cases for groups of modules. For example, we might want to test an entire form, instead of just testing each box within the form.

More information: [Integration Testing](http://softwaretestingfundamentals.com/integration-testing/)

## Incremental Testing

One of the issues with integration testing is that if a bug arises, it can be difficult to tell exactly what module introduced that bug. Incremental testing is one way of making this process easier.

With incremental testing, we slowly add one module after the next into the testing environment. This way, if a bug arises, we know which module caused the bugs to be introduced.

More Information: [Incremental Testing](https://www.tutorialspoint.com/software_testing_dictionary/incremental_testing.htm)

### Top-Down Testing

With Top-Down Testing, we begin testing at the highest possible level, and then work our way down. To have this work, we need to have a set dummy modules that we slowly replace with regular modules.

- Stub: A template of the model that will be implemented. Typically returns hard-coded values.

A stub is typically used for this. It's a module which doesn't have any logic in it. All it has, are functions which return hard coded values. Hard-coded here means nothing that was calculated, just values that we put in there. So for example, a stub might have a function "getUser(int 45)". Instead of going through and finding information about a user, it just returns a user object that we have hard-coded into it.

This way we can test our modules ability to use the user information, without having to introduce another module. Once we test everything and make sure it works, we can then add in the actual module and do our next round of testing.

### Bottom-Up Testing

Bottom-Up Testing is the opposite of Top-Down. Here we work from the bottom, and use things called drivers to make our way upwards.

- Driver: Templates which execute commands and initialize the needed variables.

When we work from bottom up, we need the logic which call our bottom modules. For example, if our module is the module with getUser(<user_id>) in it, then we need to figure out a way to properly test this. What we right is a driver, which initializes the variables, and then makes multiple calls to the functions we need it to.

So in this situation, the driver might call getUser() 1,000,000 times with random values. We would then look at the results to see if the function is working the way we want it. Once we are satisfied, we add another layer and keep going.

## Back to Back Testing

Back to Back testing is good to do when you already have a working program. With this, we run a set of tests on the system before we make a change. We then make a change, by either updating, adding, or deleting a module. We then run the same set of tests.

We now have two sets of data. The before, and the after. We compare these two sets to make sure that there are no differences. If there is a difference, we know the change did more than we like. We can then revert, or go fix the bug.

More Information: [Back to Back Testing](http://www.professionalqa.com/back-to-back-testing)

## Manual vs Automatic Testing

There are two different ways we can set up tests. We can do it manually, where we enter in values ourselves, or automatically, where we set up another system to do the test.

### Automatic

Both of these have their own merits. Automatic testing is nice because we can cover a much larger area than manual testing. We can set up a system, and have it test millions of test cases. Once we set it up, we can run it every-time we change our code, guaranteeing we didn't break anything with a new update.

This all however comes with a lot more overhead. The testing system is a system itself. This means more planning and development time.On top of this, we will have to design tests which can be done from the computer, and provide oracles to check their data. If we are testing out millions of test cases, the oracle will most likely have to be a complex algorithm.

There also comes the issue of testing the tester. What if our tester is designed incorrectly and it gives us false positives or negatives? We then spend unnecessary time chasing down phantom bugs, or deploy bad software.

### Manual

Manual testing involves a human being testing the code. They user goes in expecting to do an action. They then test to see if there is expected behavior. Bugs are noted down, and then given to developers.

These testers can be developers, stakeholders, or specially trained testers. They can more easily come up with oracles, and perform a wide range of tests.

However, humans are very slow when compared to a computer. They can only test so much of a system. Often times, this means many parts of the system don't get properly tested.

### Overall

The best way to test is to combine these two. Have a good set of automatic tests, and a good set of testers. This will allow the speed of automatic, and the ease and flexibility of manual.

## Black Box vs White Box Testing

Depending on who tests can also have a large difference on testing. In the testing world there is this idea of "white box" and black box" testing.

With black box testing, we are testing the device based on inputs and outputs. We have no idea how the program works. All we know is that we should give it a certain input, and a certain output should occur. With this type of testing, we are looking for general functionality. We want to see how the program reacts to different inputs and outputs.

White box testing however, is when we know the inner workings of a system. With this type of testing, we are trying to test the code itself. We typically develop more technical tests that try to make sure the system is coded correctly.

- [White Box Testing](http://softwaretestingfundamentals.com/white-box-testing/)
- [Black Box Testing](http://softwaretestingfundamentals.com/black-box-testing/)
